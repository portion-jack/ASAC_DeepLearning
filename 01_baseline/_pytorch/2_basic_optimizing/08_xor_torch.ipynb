{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[1,1],[1,0],[0,1],[0,0]])\n",
    "y_data = np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(x_data)\n",
    "y = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0380], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=torch.empty([2,1], requires_grad=True)\n",
    "b=torch.empty([1], requires_grad=True)\n",
    "torch.nn.init.uniform_(w)\n",
    "torch.nn.init.uniform_(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost():\n",
    "    z = torch.matmul(x,w) + b\n",
    "    c_i = F.binary_cross_entropy_with_logits(z,y)\n",
    "    c = torch.mean(c_i)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = > 0.723616898059845\n",
      "cost = > 0.7213112711906433\n",
      "cost = > 0.7191121578216553\n",
      "cost = > 0.717021644115448\n",
      "cost = > 0.7150421142578125\n",
      "cost = > 0.7131750583648682\n",
      "cost = > 0.7114218473434448\n",
      "cost = > 0.7097833752632141\n",
      "cost = > 0.7082599401473999\n",
      "cost = > 0.7068513631820679\n",
      "cost = > 0.7055566310882568\n",
      "cost = > 0.7043744921684265\n",
      "cost = > 0.7033027410507202\n",
      "cost = > 0.702338457107544\n",
      "cost = > 0.7014782428741455\n",
      "cost = > 0.7007178068161011\n",
      "cost = > 0.7000522017478943\n",
      "cost = > 0.6994757056236267\n",
      "cost = > 0.6989822387695312\n",
      "cost = > 0.6985651850700378\n",
      "cost = > 0.6982171535491943\n",
      "cost = > 0.6979310512542725\n",
      "cost = > 0.6976989507675171\n",
      "cost = > 0.6975134611129761\n",
      "cost = > 0.6973668336868286\n",
      "cost = > 0.6972519159317017\n",
      "cost = > 0.6971619129180908\n",
      "cost = > 0.6970902681350708\n",
      "cost = > 0.6970314979553223\n",
      "cost = > 0.6969802975654602\n",
      "cost = > 0.6969326734542847\n",
      "cost = > 0.6968849301338196\n",
      "cost = > 0.6968343257904053\n",
      "cost = > 0.6967787146568298\n",
      "cost = > 0.696716845035553\n",
      "cost = > 0.6966478824615479\n",
      "cost = > 0.6965718269348145\n",
      "cost = > 0.6964887976646423\n",
      "cost = > 0.6963993310928345\n",
      "cost = > 0.696304440498352\n",
      "cost = > 0.6962050199508667\n",
      "cost = > 0.6961023807525635\n",
      "cost = > 0.6959977746009827\n",
      "cost = > 0.6958924531936646\n",
      "cost = > 0.6957874298095703\n",
      "cost = > 0.6956839561462402\n",
      "cost = > 0.6955828070640564\n",
      "cost = > 0.6954847574234009\n",
      "cost = > 0.6953905820846558\n",
      "cost = > 0.6953006982803345\n",
      "cost = > 0.6952153444290161\n",
      "cost = > 0.6951346397399902\n",
      "cost = > 0.6950585842132568\n",
      "cost = > 0.6949871182441711\n",
      "cost = > 0.6949200630187988\n",
      "cost = > 0.6948570013046265\n",
      "cost = > 0.6947976350784302\n",
      "cost = > 0.6947416663169861\n",
      "cost = > 0.6946886777877808\n",
      "cost = > 0.6946382522583008\n",
      "cost = > 0.6945900321006775\n",
      "cost = > 0.694543719291687\n",
      "cost = > 0.6944989562034607\n",
      "cost = > 0.6944555640220642\n",
      "cost = > 0.6944133639335632\n",
      "cost = > 0.6943720579147339\n",
      "cost = > 0.6943315267562866\n",
      "cost = > 0.6942919492721558\n",
      "cost = > 0.6942530870437622\n",
      "cost = > 0.694214940071106\n",
      "cost = > 0.6941776275634766\n",
      "cost = > 0.6941410899162292\n",
      "cost = > 0.6941054463386536\n",
      "cost = > 0.6940706968307495\n",
      "cost = > 0.6940370202064514\n",
      "cost = > 0.694004237651825\n",
      "cost = > 0.6939725875854492\n",
      "cost = > 0.6939418911933899\n",
      "cost = > 0.6939123272895813\n",
      "cost = > 0.693884015083313\n",
      "cost = > 0.6938565373420715\n",
      "cost = > 0.6938302516937256\n",
      "cost = > 0.6938050389289856\n",
      "cost = > 0.693780779838562\n",
      "cost = > 0.6937574148178101\n",
      "cost = > 0.6937350034713745\n",
      "cost = > 0.6937134265899658\n",
      "cost = > 0.693692684173584\n",
      "cost = > 0.6936725974082947\n",
      "cost = > 0.6936533451080322\n",
      "cost = > 0.6936346292495728\n",
      "cost = > 0.6936166286468506\n",
      "cost = > 0.6935992240905762\n",
      "cost = > 0.6935823559761047\n",
      "cost = > 0.6935660243034363\n",
      "cost = > 0.6935502290725708\n",
      "cost = > 0.6935349702835083\n",
      "cost = > 0.693520188331604\n",
      "cost = > 0.6935058832168579\n",
      "cost = > 0.69349205493927\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam([w,b], lr=0.01)\n",
    "for epoch in range(100):\n",
    "    c = cost()\n",
    "    optimizer.zero_grad()\n",
    "    c.backward()\n",
    "    optimizer.step()\n",
    "    print(f'cost = > {c.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hxFn(x_data):\n",
    "    xd = torch.FloatTensor(x_data)\n",
    "    z = torch.matmul(xd,w) + b\n",
    "    hx = torch.sigmoid(z)\n",
    "    return (hx.detach().numpy()>0.5) + 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hxFn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fedde54ce020962bd3c30003bddb8a1c5bd9c5a066c739d1bc484f734442d14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
